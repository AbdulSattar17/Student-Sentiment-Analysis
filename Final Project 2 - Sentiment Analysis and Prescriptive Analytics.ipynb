{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724f1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\\\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cf842aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    \n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828e00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.title.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50ccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50062f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(feed):\n",
    "    \n",
    "    word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "    model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))\n",
    "    sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "    sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))\n",
    "    new_data = pd.DataFrame(data={'title': [feed], 'rate': [-1]})\n",
    "    \n",
    "    file_weighting = new_data.copy()\n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "    tfidf.fit(file_weighting.title)\n",
    "    features = pd.Series(tfidf.get_feature_names())\n",
    "    transformed = tfidf.transform(file_weighting.title)\n",
    "\n",
    "    replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\n",
    "    \n",
    "    sentiment_score = []\n",
    "    for i in range(len(replaced_tfidf_scores)):\n",
    "        score = 0\n",
    "        for j in range(len(replaced_tfidf_scores[i])):\n",
    "            word = file_weighting.iloc[i].title.split()[j]\n",
    "            if word in sentiment_dict:\n",
    "                score += sentiment_dict[word] * replaced_tfidf_scores[i][j]\n",
    "        sentiment_score.append(score)\n",
    "    new_data['sentiment_rate'] = sentiment_score\n",
    "    new_data['prediction'] = (new_data.sentiment_rate>0).astype('int8')\n",
    "    \n",
    "    print(new_data)\n",
    "    \n",
    "    if new_data.prediction[0] == 0:\n",
    "        return \"Negative\"\n",
    "    elif new_data.prediction[0] == 1:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4267015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prescribe_sentiment(feedback):\n",
    "\n",
    "    # Load the dataset of feedbacks into a variable named df\n",
    "    df = pd.read_csv('feedbacks_and_prescriptions.csv')\n",
    "    \n",
    "    # Create a pipeline to vectorize the feedbacks and train a linear SVM model\n",
    "    text_clf = Pipeline([('tfidf', TfidfVectorizer()), ('clf', LinearSVC())])\n",
    "    \n",
    "    # Fitting model on data\n",
    "    text_clf.fit(df['feedbacks'], df['precriptions'])\n",
    "    \n",
    "    # Getting predictions\n",
    "    new_feedback = feedback\n",
    "    predicted_solution = text_clf.predict([new_feedback])[0]\n",
    "    return 'System Prescription: ' + '\\n' + predicted_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cc2e1c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:17:39: Starting Bokeh server version 2.4.2 (running on Tornado 6.1)\n",
      "INFO - 21:17:39: User authentication hooks NOT provided (default user enabled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:56249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<panel.io.server.Server at 0x229197c3820>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:17:40: 200 GET / (::1) 798.02ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/alerts.css (::1) 2.34ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/dataframe.css (::1) 6.59ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/debugger.css (::1) 13.53ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/card.css (::1) 6.29ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/json.css (::1) 8.47ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/loading.css (::1) 9.42ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/widgets.css (::1) 18.62ms\n",
      "INFO - 21:17:40: 200 GET /static/js/bokeh-gl.min.js?v=863c26b3d7cbcf2a0dbf119589404b3ca66734754cd0af1d6e6ca17679ae711126917f171667194a6f04765eba06d9eb2d7d1f2ba7ef8fee420b9244557386f8 (::1) 5.37ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/css/markdown.css (::1) 12.75ms\n",
      "INFO - 21:17:40: 200 GET /static/js/bokeh-widgets.min.js?v=0ede1975746c96e47b24a08c83a45a9282b6524986185f620debadba5132e16c43f941626151d70d779dde7ff63ef84830eb4b277291752aea5176a795b00cec (::1) 21.84ms\n",
      "INFO - 21:17:40: 200 GET /static/js/bokeh-tables.min.js?v=e075943aa7fac687b27889393d32dde4c6dd9fc8ca7eeb3864ce96011372ea45d3807d8a2d15b322b051170360eda59a5cd9384219c4b150b271b864df4b07d3 (::1) 24.96ms\n",
      "INFO - 21:17:40: 200 GET /static/extensions/panel/panel.min.js?v=0f8d7ed5b1114c4abe733b1a6a147ff6e923df5ad710f6d6eb9b8b30129543eb (::1) 29.27ms\n",
      "INFO - 21:17:40: 200 GET /static/js/bokeh.min.js?v=b3e0592a1e90448fa40dcddd5cd5217dcd6b3c7dd368020f6a8e4be4fdd1adbdeb2824eb75ab4f5120c80dc7684f8ff2aa2f8b00d6f393108c96d2f6f2cf0297 (::1) 89.76ms\n",
      "INFO - 21:17:41: 101 GET /ws (::1) 1.00ms\n",
      "INFO - 21:17:41: WebSocket connection opened\n",
      "INFO - 21:17:41: ServerConnection created\n",
      "WARNING - 21:17:41: 404 GET /favicon.ico (::1) 0.99ms\n",
      "INFO - 21:17:51: loading Word2Vec object from word2vec.model\n",
      "INFO - 21:17:51: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 21:17:51: setting ignored attribute cum_table to None\n",
      "INFO - 21:17:51: Word2Vec lifecycle event {'fname': 'word2vec.model', 'datetime': '2023-02-13T21:17:51.421721', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  rate  sentiment_rate  \\\n",
      "0  this is not excepable as the students are not ...    -1       -7.349486   \n",
      "\n",
      "   prediction  \n",
      "0           0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:17:52: loading Word2Vec object from word2vec.model\n",
      "INFO - 21:17:52: loading wv recursively from word2vec.model.wv.* with mmap=None\n",
      "INFO - 21:17:52: setting ignored attribute cum_table to None\n",
      "INFO - 21:17:52: Word2Vec lifecycle event {'fname': 'word2vec.model', 'datetime': '2023-02-13T21:17:52.434732', 'gensim': '4.1.2', 'python': '3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22000-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           title  rate  sentiment_rate  prediction\n",
      "0  we will work on it to improve    -1        0.030601           1\n",
      "-------------------------------\n",
      "System Prescription: \n",
      "student seems unsatisfied. a meeting can be arranged with the student for complete details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:18:04: WebSocket connection closed: code=1001, reason=None\n"
     ]
    }
   ],
   "source": [
    "import panel as pn \n",
    "\n",
    "text_input1 = pn.widgets.TextAreaInput(name=\"Enter Student's Feedback:\", width=500, height=150)\n",
    "text_input2 = pn.widgets.TextAreaInput(name=\"Enter Teacher's Feedback:\", width=500, height=150)\n",
    "submit_button1 = pn.widgets.Button(name=\"Submit Student Feedback\", button_type=\"primary\", width=160)\n",
    "submit_button2 = pn.widgets.Button(name=\"Submit Teachers Feedback\", button_type=\"primary\", width=160)\n",
    "submit_button3 = pn.widgets.Button(name=\"Get Prescription\", button_type=\"primary\")\n",
    "feedback_display1 = pn.widgets.StaticText(value=\"\", width=500, height=25, background='lightblue')\n",
    "feedback_display2 = pn.widgets.StaticText(value=\"\", width=500, height=25, background='lightblue')\n",
    "feedback_display3 = pn.widgets.StaticText(value=\"System Prescription: \", width=500, height=150, background='lightblue')\n",
    "info_button1 = pn.widgets.Button(name=\"?\", button_type=\"success\", width=20)\n",
    "info_button2 = pn.widgets.Button(name=\"?\", button_type=\"success\", width=20)\n",
    "\n",
    "\n",
    "@submit_button1.on_click\n",
    "def submit_clicked1(event):\n",
    "    value1 = text_input1.value\n",
    "    if len(value1) < 1:\n",
    "        feedback_display1.value = \"Invalid Input\"\n",
    "    else:\n",
    "        feedback1 = classify_sentiment(value1.lower())\n",
    "        feedback_display1.value = feedback1\n",
    "\n",
    "@submit_button2.on_click\n",
    "def submit_clicked2(event):\n",
    "    value2 = text_input2.value\n",
    "    if len(value2) < 1:\n",
    "        feedback_display2.value = \"Invalid Input\"\n",
    "    else:\n",
    "        feedback2 = classify_sentiment(value2.lower())\n",
    "        feedback_display2.value = feedback2\n",
    "    \n",
    "@submit_button3.on_click\n",
    "def submit_clicked3(event):\n",
    "    value3 = text_input1.value\n",
    "    feedback3 = prescribe_sentiment(value3.lower())\n",
    "    print('-------------------------------')\n",
    "    print(feedback3)\n",
    "    feedback_display3.value = feedback3\n",
    "    \n",
    "@info_button1.on_click\n",
    "def update_text1(event):\n",
    "    if len(info_button1.name) == 1:\n",
    "        info_button1.name = 'Kindly add the feedback in the above text field to get it classified'\n",
    "    else:\n",
    "        info_button1.name = '?'\n",
    "\n",
    "@info_button2.on_click\n",
    "def update_text2(event):\n",
    "    if len(info_button2.name) == 1:\n",
    "        info_button2.name = 'Kindly add the feedback in the above text field to get it classified'\n",
    "    else:\n",
    "        info_button2.name = '?'\n",
    "\n",
    "\n",
    "heading = pn.pane.HTML(\"<h1 style='text-align:center;'>Advisory System Using Sentiment Analysis</h1>\")\n",
    "\n",
    "pn.Column(\n",
    "pn.Row(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", heading),\n",
    "pn.Row(text_input1, \"\", \"\", \"\", \"\", \"\", text_input2),\n",
    "pn.Row(feedback_display1, \"\", \"\", \"\", \"\", \"\", feedback_display2),\n",
    "pn.Row(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", submit_button1, info_button1, \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", submit_button2, info_button2),\n",
    "pn.Row(\"\"),\n",
    "pn.Row(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", feedback_display3),\n",
    "pn.Row(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \n",
    "       \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", submit_button3),\n",
    "pn.Row(\"\"),\n",
    "background='lightgray'\n",
    ").show(view='popup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "968c9e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presc_df = pd.read_excel('feedbacks_and_prescriptions.xlsx')\n",
    "# presc_df.feedbacks = [\" \".join(x.lower().split()) for x in presc_df.feedbacks]\n",
    "# presc_df.precriptions = [\" \".join(x.lower().split()) for x in presc_df.precriptions]\n",
    "# print(len(presc_df))\n",
    "# presc_df = presc_df.drop_duplicates(subset='feedbacks', keep=\"first\")\n",
    "# print(len(presc_df))\n",
    "# presc_df.to_csv('feedbacks_and_prescriptions.csv', index=False)\n",
    "# presc_df\n",
    "\n",
    "\n",
    "# classify_sentiment('this is not excepable as the students are not getting proper responses from the teachers'.lower())\n",
    "\n",
    "# I am unable to pay my university fees because I have no money left"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
