{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6dd5ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow\n",
    "# ! pip install transformers\n",
    "# ! pip install torch\n",
    "# ! pip install pytorch\n",
    "\n",
    "# import torch\n",
    "# print(torch.__version__)\n",
    "# conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "724f1733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "from re import sub\n",
    "from time import time \n",
    "from unidecode import unidecode\n",
    "from gensim.models import Word2Vec\n",
    "from collections import defaultdict\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54811a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data():\n",
    "    \n",
    "    df = pd.read_excel(r'sample_feedbacks.xlsx')\n",
    "    df.target.replace([4,2], 1, inplace = True)\n",
    "    df.target.replace(0, -1, inplace = True)\n",
    "\n",
    "    df['length'] = [len(x) for x in df.feedbacks]\n",
    "\n",
    "    df.rename({'feedbacks': 'description', 'target': 'rate'}, axis=1, inplace=True)\n",
    "    \n",
    "    df.to_csv('student_feebacks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "621c5e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text, remove_polish_letters):\n",
    "    ''' Pre process and convert texts to a list of words \n",
    "    method inspired by method from eliorc github repo: https://github.com/eliorc/Medium/blob/master/MaLSTM.ipynb'''\n",
    "    # text = remove_polish_letters(text)\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = sub(r\"[^A-Za-z0-9^,!?.\\/'+]\", \" \", text)\n",
    "    text = sub(r\"\\+\", \" plus \", text)\n",
    "    text = sub(r\",\", \" \", text)\n",
    "    text = sub(r\"\\.\", \" \", text)\n",
    "    text = sub(r\"!\", \" ! \", text)\n",
    "    text = sub(r\"\\?\", \" ? \", text)\n",
    "    text = sub(r\"'\", \" \", text)\n",
    "    text = sub(r\":\", \" : \", text)\n",
    "    text = sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de7c5947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing():\n",
    "    \n",
    "    file = pd.read_csv(\"student_feebacks.csv\")\n",
    "    \n",
    "    file_cleaned = file.dropna().drop_duplicates().reset_index(drop=True).rename(columns={'description':'title'})\n",
    "    file_cleaned = file_cleaned[file_cleaned.rate!=0]\n",
    "    \n",
    "    file_cleaned.title = file_cleaned.title.apply(lambda x: text_to_word_list(x, unidecode))\n",
    "    file_model = file_cleaned.copy()\n",
    "    file_model = file_model[file_model.title.str.len()>1]\n",
    "    \n",
    "    sent = [row for row in file_model.title]\n",
    "    phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "    bigram = Phraser(phrases)\n",
    "    sentences = bigram[sent]\n",
    "    \n",
    "    w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "    start = time()\n",
    "\n",
    "    w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "\n",
    "    print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "    \n",
    "    start = time()\n",
    "\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "    print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "    w2v_model.init_sims(replace=True)\n",
    "    \n",
    "    w2v_model.save(\"word2vec.model\")\n",
    "    \n",
    "    file_export = file_model.copy()\n",
    "    file_export['old_title'] = file_export.title\n",
    "    file_export.old_title = file_export.old_title.str.join(' ')\n",
    "    file_export.title = file_export.title.apply(lambda x: ' '.join(bigram[x]))\n",
    "    file_export.rate = file_export.rate.astype('int8')\n",
    "    \n",
    "    file_export[['title', 'rate']].to_csv('cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6aa671ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_kmeans():\n",
    "\n",
    "    word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "\n",
    "    model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))\n",
    "\n",
    "    positive_cluster_index = 1\n",
    "    positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "    negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]\n",
    "\n",
    "    words = pd.DataFrame(word_vectors.index_to_key)\n",
    "    words.columns = ['words']\n",
    "    words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "    words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "    words.cluster = words.cluster.apply(lambda x: x[0])\n",
    "\n",
    "    words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "    words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "    words['sentiment_coeff'] = words.closeness_score * words.cluster_value\n",
    "\n",
    "    words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "828e00f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.title.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b50ccbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73fdbfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions():\n",
    "    \n",
    "    final_file = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "    sentiment_map = pd.read_csv('sentiment_dictionary.csv')\n",
    "    sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))\n",
    "\n",
    "    file_weighting = final_file.copy()\n",
    "\n",
    "    tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "    tfidf.fit(file_weighting.title)\n",
    "    features = pd.Series(tfidf.get_feature_names())\n",
    "    transformed = tfidf.transform(file_weighting.title)\n",
    "\n",
    "    replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate\n",
    "\n",
    "    replaced_closeness_scores = file_weighting.title.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))\n",
    "\n",
    "    replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.title, file_weighting.rate]).T\n",
    "    replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
    "    replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "    replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "    replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]\n",
    "\n",
    "    predicted_classes = replacement_df.prediction\n",
    "    y_test = replacement_df.sentiment\n",
    "\n",
    "    conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
    "    # print('Confusion Matrix')\n",
    "    # display(conf_matrix)\n",
    "\n",
    "    test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
    "\n",
    "    # print('\\n \\n Scores')\n",
    "    scores = pd.DataFrame(data=[test_scores])\n",
    "    scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
    "    scores = scores.T\n",
    "    scores.columns = ['scores']\n",
    "    # display(scores)\n",
    "    \n",
    "    print(replacement_df[replacement_df['prediction'] == 0]['sentence'].reset_index(drop=True)[59])\n",
    "    print('-----------------------------------------------')\n",
    "    print(replacement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abada2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prescriptive_analytics():\n",
    "\n",
    "    # Load the GPT-2 tokenizer and model\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    # Load the student feedback dataset\n",
    "    feedbacks = [\n",
    "        \"I'm not able to pay my university fees\",\n",
    "        \"Course outline is not well defined\",\n",
    "        \"Teachers are very good\",\n",
    "        \"Teachers are not collaborative\",\n",
    "        \"teaching style is not good\"\n",
    "    ]\n",
    "\n",
    "    # Generate text for each feedback in the dataset\n",
    "    for feedback in feedbacks:\n",
    "        # Encode the input prompt as a sequence of tokens\n",
    "        prompt = \"What is the solution for \" + feedback\n",
    "        input_ids = tf.constant(tokenizer.encode(prompt, return_tensors='tf'))\n",
    "\n",
    "        # Generate text with the GPT-2 model\n",
    "        outputs = model.generate(input_ids)\n",
    "        text = tokenizer.decode(outputs[0].numpy(), skip_special_tokens=True)\n",
    "        print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03c0748a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the examination system of the university is very impressive the sitting plan of he students is made in such a way that no 2 students of same class give the exam in same room or even sometimes same blocks through this students also get to_know and visit different blocks of the university the checking is also fair\n",
      "-----------------------------------------------\n",
      "                                       sentiment_coeff  \\\n",
      "0    [-1.0319097960186612, 0, 1.036606611948171, 0,...   \n",
      "1    [-1.035325828604643, -1.0220210938944394, 1.01...   \n",
      "2    [-1.0391542186665983, 0, -1.027270156328658, -...   \n",
      "3    [1.036643297408026, -1.041125775113667, 1.0110...   \n",
      "4    [-1.0281609632960544, 1.044951808199921, 1.036...   \n",
      "..                                                 ...   \n",
      "119  [0, 1.044951808199921, 1.024796561358173, 0, 0...   \n",
      "120  [1.0171321511527047, 0, 0, 1.044951808199921, ...   \n",
      "121  [-1.0655187303207156, 0, 0, -1.039767932814708...   \n",
      "122  [1.0150974417255805, 1.045943319235544, 0, -1....   \n",
      "123  [0, 0, 1.044951808199921, 1.036643297408026, 1...   \n",
      "\n",
      "                                          tfidf_scores  \\\n",
      "0    [3.2633643798407643, 4.7297014486341915, 2.427...   \n",
      "1    [4.442019376182411, 3.4304184645039304, 2.6502...   \n",
      "2    [3.2633643798407643, 4.7297014486341915, 2.737...   \n",
      "3    [1.5378542961539101, 1.9781661355922426, 3.882...   \n",
      "4    [3.05572501506252, 1.653926467406664, 1.537854...   \n",
      "..                                                 ...   \n",
      "119  [4.7297014486341915, 3.307852934813328, 2.8838...   \n",
      "120  [4.036554268074246, 4.7297014486341915, 5.1351...   \n",
      "121  [11.618960635150048, 4.7297014486341915, 5.135...   \n",
      "122  [4.036554268074246, 4.442019376182411, 5.13516...   \n",
      "123  [4.7297014486341915, 5.135166556742356, 3.3078...   \n",
      "\n",
      "                                              sentence  sentiment  \\\n",
      "0    teacher are_punctual but they_should also give...          0   \n",
      "1    excellent lectures are delivered by teachers a...          1   \n",
      "2    teachers give_us all the information required ...          1   \n",
      "3                                    good and punctual          1   \n",
      "4                                           it is good          1   \n",
      "..                                                 ...        ...   \n",
      "119      paper_checking is very hard remaining is good          1   \n",
      "120  excellent_but checking procedure is not except...          0   \n",
      "121  the examination system of the university is ve...          1   \n",
      "122  its very_bad thing not sowing answer of mcq in...          0   \n",
      "123  marks distribution is good but paper_checking ...          0   \n",
      "\n",
      "     sentiment_rate  prediction  \n",
      "0         -9.538627           0  \n",
      "1         -8.482384           0  \n",
      "2        -14.456536           0  \n",
      "3          3.459832           1  \n",
      "4          0.180703           1  \n",
      "..              ...         ...  \n",
      "119       11.462685           1  \n",
      "120       -7.929218           0  \n",
      "121     -155.051762           0  \n",
      "122        3.642479           1  \n",
      "123        7.758045           1  \n",
      "\n",
      "[124 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArsalRahim\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\ArsalRahim\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import_data()\n",
    "# data_preprocessing()\n",
    "# training_kmeans()\n",
    "get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c3aa20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b9939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6a2a4eb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:03:48: Starting Bokeh server version 2.4.2 (running on Tornado 6.1)\n",
      "INFO - 16:03:48: User authentication hooks NOT provided (default user enabled)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching server at http://localhost:60697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bokeh.server.server.Server at 0x1b2a9113670>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 16:03:49: 200 GET / (::1) 194.32ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/alerts.css (::1) 8.97ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/markdown.css (::1) 5.86ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/card.css (::1) 13.18ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/dataframe.css (::1) 15.96ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/debugger.css (::1) 20.95ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/json.css (::1) 23.94ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/loading.css (::1) 26.74ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/css/widgets.css (::1) 3.99ms\n",
      "INFO - 16:03:49: 200 GET /static/js/bokeh-gl.min.js?v=863c26b3d7cbcf2a0dbf119589404b3ca66734754cd0af1d6e6ca17679ae711126917f171667194a6f04765eba06d9eb2d7d1f2ba7ef8fee420b9244557386f8 (::1) 7.98ms\n",
      "INFO - 16:03:49: 200 GET /static/extensions/panel/panel.min.js?v=d4fabbf73758512562f5c3b6a3b77456c94ac424b7443f9aee6c61b7919cc2df (::1) 7.98ms\n",
      "INFO - 16:03:49: 200 GET /static/js/bokeh-widgets.min.js?v=0ede1975746c96e47b24a08c83a45a9282b6524986185f620debadba5132e16c43f941626151d70d779dde7ff63ef84830eb4b277291752aea5176a795b00cec (::1) 10.57ms\n",
      "INFO - 16:03:49: 200 GET /static/js/bokeh-tables.min.js?v=e075943aa7fac687b27889393d32dde4c6dd9fc8ca7eeb3864ce96011372ea45d3807d8a2d15b322b051170360eda59a5cd9384219c4b150b271b864df4b07d3 (::1) 14.88ms\n",
      "INFO - 16:03:49: 200 GET /static/js/bokeh.min.js?v=b3e0592a1e90448fa40dcddd5cd5217dcd6b3c7dd368020f6a8e4be4fdd1adbdeb2824eb75ab4f5120c80dc7684f8ff2aa2f8b00d6f393108c96d2f6f2cf0297 (::1) 30.92ms\n",
      "INFO - 16:03:49: 101 GET /ws (::1) 1.00ms\n",
      "INFO - 16:03:49: WebSocket connection opened\n",
      "INFO - 16:03:49: ServerConnection created\n",
      "WARNING - 16:03:49: 404 GET /favicon.ico (::1) 0.00ms\n",
      "INFO - 16:03:53: WebSocket connection closed: code=1001, reason=None\n"
     ]
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "def test_function(value1, value2):\n",
    "    print(\"The value entered in the first textbox is: \", value1)\n",
    "    return \"Shaka laka boom boom\"\n",
    "\n",
    "text_input1 = pn.widgets.TextAreaInput(name=\"Enter Student's Feedback:\", width=500, height=200)\n",
    "text_input2 = pn.widgets.TextAreaInput(name=\"Enter Teacher's Feedback:\", width=500, height=200)\n",
    "submit_button1 = pn.widgets.Button(name=\"Submit Student Feedback\", button_type=\"primary\")\n",
    "submit_button2 = pn.widgets.Button(name=\"Submit Teachers Feedback\", button_type=\"primary\")\n",
    "feedback_display = pn.widgets.StaticText(value=\"\", width=500, background='lightgrey')\n",
    "\n",
    "@submit_button1.on_click\n",
    "def submit_clicked1(event):\n",
    "    value1 = text_input1.value\n",
    "    feedback = test_function(value1, \"\")\n",
    "    feedback_display.value = feedback\n",
    "\n",
    "@submit_button2.on_click\n",
    "def submit_clicked2(event):\n",
    "    value2 = text_input2.value\n",
    "    test_function(\"\", value2)\n",
    "\n",
    "pn.Column(\n",
    "pn.Row(text_input1),\n",
    "pn.Row(submit_button1),\n",
    "pn.Row(feedback_display),\n",
    "pn.Row(\"\"),\n",
    "pn.Row(text_input2),\n",
    "pn.Row(submit_button2)\n",
    ").show(view='popup')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
